---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.0
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python}
import numpy as np
import pandas as pd
from glmnet import MultiGaussNet
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
import statsmodels.api as sm
import rpy2
# %load_ext rpy2.ipython

```

```{python}
n, p, q, nlambda = 103, 17, 3, 100
rng = np.random.default_rng(0)
X = rng.standard_normal((n, p))
O = rng.standard_normal((n, q)) * 0.2
W = rng.integers(2, 6, size=n)
W[:20] = 3
Y = rng.standard_normal((n, q)) * 5
D = np.column_stack([Y, O, W])
response_id = [f'response[{i}]' for i in range(q)]
offset_id = [f'offset[{i}]' for i in range(q)]
Df = pd.DataFrame(D, columns=response_id + offset_id + ['weight'])
Df
```

# Use one of the C++ paths

## Without CV

```{python}
GN2 = MultiGaussNet(response_id=response_id,
                    offset_id=offset_id,
                    nlambda=nlambda,
             ).fit(X, Df)
```

```{r magic_args="-i X,Y,O,W,nlambda -o L,C1,C2,C3"}
library(glmnet)
GN2 = glmnet(X, Y, 
             #weights=W, 
             offset=O,
             family='mgaussian',
             nlambda=nlambda)
C = coef(GN2)
C1 = as.matrix(C$y1)
C2 = as.matrix(C$y2)
C3 = as.matrix(C$y3)
L = GN2$lambda
```

```{python}
C = np.array([C1,C2,C3]).T
assert np.allclose(C[:,1:], GN2.coefs_)
assert np.allclose(C[:,0], GN2.intercepts_)
```

```{python}
GN2 = MultiGaussNet(response_id=response_id,
             weight_id='weight',
                    nlambda=nlambda
             )
GN2.fit(X, Df)
```

```{r magic_args="-o L,C1,C2,C3"}
GN2 = glmnet(X, Y, weights=W, 
             family='mgaussian',
             nlambda=nlambda)
C = coef(GN2)
C1 = as.matrix(C$y1)
C2 = as.matrix(C$y2)
C3 = as.matrix(C$y3)
L = GN2$lambda
```

```{python}
C = np.array([C1,C2,C3]).T
assert np.allclose(C[:,1:], GN2.coefs_)
assert np.allclose(C[:,0], GN2.intercepts_)
```

```{python}
GN2 = MultiGaussNet(response_id=response_id,
             offset_id=offset_id,
                    weight_id='weight',
             ).fit(X, Df)

```

```{r magic_args="-o L,C1,C2,C3"}
GN2 = glmnet(X, 
             Y, 
             weights=W, 
             offset=O,
             family='mgaussian',
             nlambda=nlambda)
C = coef(GN2)
C1 = as.matrix(C$y1)
C2 = as.matrix(C$y2)
C3 = as.matrix(C$y3)
L = GN2$lambda

```

```{python}
C = np.array([C1,C2,C3]).T
assert np.allclose(C[:,1:], GN2.coefs_)
assert np.allclose(C[:,0], GN2.intercepts_)
```

## Now with CV, first no weights

```{python}
GN3 = MultiGaussNet(response_id=response_id,
                    offset_id=offset_id,
                   ).fit(X, Df)

```

Capture the fold ids

```{python}
cv = KFold(5, random_state=0, shuffle=True)
foldid = np.empty(n)
for i, (train, test) in enumerate(cv.split(np.arange(n))):
    foldid[test] = i+1
```

## With an offset using `fraction`

```{python}
predictions, scores = GN3.cross_validation_path(X, Df, cv=cv, alignment='fraction');
```

```{python}
GN3.plot_cross_validation(score='Mean Squared Error', xvar='lambda')
```

```{r magic_args="-i foldid -o CVM,CVSD"}
foldid = as.integer(foldid)
W = as.numeric(W)
GCV = cv.glmnet(X,
                Y, 
                offset=O,
                foldid=foldid,
                family="mgaussian",
		        alignment="fraction",
                nlambda=nlambda,
		        grouped=TRUE)
plot(GCV)
CVM = GCV$cvm
CVSD = GCV$cvsd
```

```{python}
assert np.allclose(GN3.cv_scores_['Mean Squared Error'], CVM)
assert np.allclose(GN3.cv_scores_['SD(Mean Squared Error)'], CVSD) 
```

```{python}
GN3.cv_scores_['Mean Squared Error']*q, CVM
```

## With an offset using `lambda`

```{python}
GN3 = MultiGaussNet(response_id=response_id,
             offset_id=offset_id,
            ).fit(X, Df)
predictions, scores = GN3.cross_validation_path(X, Df, cv=cv, alignment='lambda');
```

```{python}
GN3.plot_cross_validation(score='Mean Squared Error', xvar='lambda')
```

```{r magic_args="-i foldid -o CVM,CVSD"}
foldid = as.integer(foldid)
W = as.numeric(W)
GCV = cv.glmnet(X,
                Y, 
                offset=O,
                foldid=foldid,
                family='mgaussian',
                nlambda=nlambda,
		alignment="lambda",
		grouped=TRUE)
plot(GCV)
CVM = GCV$cvm
CVSD = GCV$cvsd
```

```{python}
assert np.allclose(GN3.cv_scores_['Mean Squared Error'], CVM)
assert np.allclose(GN3.cv_scores_['SD(Mean Squared Error)'], CVSD) 
```

## With an offset and weight using `fraction`

```{python}
GN4 = MultiGaussNet(response_id=response_id,
             offset_id=offset_id,
	         weight_id='weight',
               ).fit(X, Df)
predictions, scores = GN4.cross_validation_path(X, Df, cv=cv, alignment='fraction');
```

```{python}
GN4.plot_cross_validation(score='Mean Squared Error', xvar='lambda')
```

```{r magic_args="-i foldid -o CVM,CVSD"}
foldid = as.integer(foldid)
W = as.numeric(W)
GCV = cv.glmnet(X,
                Y, 
                offset=O,
                weights=W,
                foldid=foldid,
		        alignment="fraction",
                family='mgaussian',
                nlambda=nlambda,
		        grouped=TRUE)
plot(GCV)
CVM = GCV$cvm
CVSD = GCV$cvsd
```

```{python}
assert np.allclose(GN4.cv_scores_['Mean Squared Error'], CVM)
assert np.allclose(GN4.cv_scores_['SD(Mean Squared Error)'], CVSD) 
```

## With an offset and weight using `lambda`

```{python}
GN4 = MultiGaussNet(response_id=response_id,
               offset_id=offset_id,
               weight_id='weight',
               ).fit(X, Df)
predictions, scores = GN4.cross_validation_path(X, Df, cv=cv, alignment='lambda');
```

```{python}
GN4.plot_cross_validation(score='Mean Squared Error', xvar='lambda')
```

```{r magic_args="-i foldid -o CVM,CVSD"}
foldid = as.integer(foldid)
W = as.numeric(W)
GCV = cv.glmnet(X,
                Y, 
                offset=O,
                weights=W,
                foldid=foldid,
        		alignment="lambda",
                family='mgaussian',
        		grouped=TRUE)
plot(GCV)
CVM = GCV$cvm
CVSD = GCV$cvsd
```

```{python}
assert np.allclose(GN4.cv_scores_['Mean Squared Error'], CVM)
assert np.allclose(GN4.cv_scores_['SD(Mean Squared Error)'], CVSD) 
```



```{python}

```
